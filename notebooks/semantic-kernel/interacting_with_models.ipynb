{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with Large Language Models using Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to interact with large language models (LLMs) using the Microsoft Semantic Kernel in .NET.\n",
    "\n",
    "**Objectives:**\n",
    "- Understand how to set up Semantic Kernel for LLM interaction in .NET.\n",
    "- Learn to configure and connect to different model providers (OpenAI, Azure OpenAI, GitHub models).\n",
    "- Use model parameters to customize model behavior.\n",
    "- Send prompts to LLMs and receive responses.\n",
    "- Use prompt templates and kernel arguments for dynamic, reusable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we will set up the Semantic Kernel environment and configure it to use different LLM providers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Install NuGet packages\n",
    "\n",
    "To get started with Semantic Kernel, you need to install the required NuGet packages. These packages provide the core functionality for interacting with AI models and managing environment variables. Specifically:\n",
    "- `Microsoft.SemanticKernel` enables you to build and run AI-powered workflows.\n",
    "- `DotNetEnv` allows you to load environment variables from a `.env` file, making it easier to manage secrets and configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 3.1.0</span></li><li><span>Microsoft.SemanticKernel, 1.55.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.55.0\"\n",
    "#r \"nuget: DotNetEnv, 3.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Read environment variables\n",
    "\n",
    "  In this step, we load these variables from a `.env` file (if present) so that they can be accessed by the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from d:\\personal\\aiagent-workshop\\notebooks\\semantic-kernel\\../..\\.env\r\n"
     ]
    }
   ],
   "source": [
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "\n",
    "var envFilePath = Path.Combine(Environment.CurrentDirectory, \"../..\", \".env\");\n",
    "if (File.Exists(envFilePath))\n",
    "{\n",
    "    Env.Load(envFilePath);\n",
    "    Console.WriteLine($\"Loaded environment variables from {envFilePath}\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine($\"No .env file found at {envFilePath}\");\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Instantiate the Kernel\n",
    "\n",
    "The Semantic Kernel is the core component that orchestrates AI services and plugins. In this step, we create and configure a Kernel instance, which will be used to interact with AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.ClientModel;\n",
    "using OpenAI;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using System.Text;\n",
    "\n",
    "OpenAIClient client = null;\n",
    "if(Environment.GetEnvironmentVariable(\"USE_AZURE_OPENAI\") == \"true\")\n",
    "{\n",
    "    // Configure Azure OpenAI client\n",
    "    var azureEndpoint = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\");\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey), new OpenAIClientOptions { Endpoint = new Uri(azureEndpoint) });\n",
    "}\n",
    "else if(Environment.GetEnvironmentVariable(\"USE_OPENAI\") == \"true\")\n",
    "{\n",
    "    // Configure OpenAI client\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey));\n",
    "}\n",
    "else if(Environment.GetEnvironmentVariable(\"USE_GITHUB\") == \"true\")\n",
    "{\n",
    "    // Configure GitHub model client\n",
    "    var uri = Environment.GetEnvironmentVariable(\"GITHUB_MODEL_ENDPOINT\");\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"GITHUB_TOKEN\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey), new OpenAIClientOptions { Endpoint = new Uri(uri) });\n",
    "}\n",
    "\n",
    "var modelId = Environment.GetEnvironmentVariable(\"MODEL\");\n",
    "// Create a chat completion service\n",
    "var builder = Kernel.CreateBuilder();\n",
    "builder.AddOpenAIChatCompletion(modelId, client);\n",
    "\n",
    "// Get the chat completion service\n",
    "Kernel kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling LLMs\n",
    "\n",
    "This section demonstrates how to call different LLMs using the Semantic Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Call the Kernel\n",
    "\n",
    "In this step, we send a prompt to the Semantic Kernel and receive a response from the AI model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is **Paris**.\r\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "//call the kernel to get a response\n",
    "var prompt = \"What is the capital of France?\";\n",
    "var response = await kernel.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"Response: {response}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Use Prompt Templates and Kernel Arguments\n",
    "\n",
    "Prompt templates allow you to create reusable prompts with placeholders for dynamic values. Kernel arguments let you pass values to these placeholders at runtime, making your prompts flexible and powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Japan is **Tokyo**.\r\n"
     ]
    }
   ],
   "source": [
    "// Define a prompt template with a placeholder\n",
    "string template = \"What is the capital of {{$country}}?\";\n",
    "\n",
    "// Create a function from the prompt template\n",
    "var promptTemplateConfig = new PromptTemplateConfig(template);\n",
    "var promptTemplateFactory = new KernelPromptTemplateFactory();\n",
    "var promptTemplate = promptTemplateFactory.Create(promptTemplateConfig);\n",
    "var capitalFunction = kernel.CreateFunctionFromPrompt(template);\n",
    "\n",
    "// Prepare kernel arguments\n",
    "var arguments = new KernelArguments\n",
    "{\n",
    "    [\"country\"] = \"Japan\"\n",
    "};\n",
    "\n",
    "// Call the kernel with the function and arguments\n",
    "var capitalResponse = await kernel.InvokeAsync(capitalFunction, arguments);\n",
    "Console.WriteLine($\"Response: {capitalResponse}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Try with another country\n",
    "\n",
    "You can reuse the same prompt template and function with different arguments to get answers for other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Brazil is **Brasília**. It officially became the capital on **April 21, 1960**, replacing Rio de Janeiro. Designed by architect **Oscar Niemeyer** and urban planner **Lúcio Costa**, Brasília was built to promote the development of the interior of the country and is known for its modernist architecture and unique city layout.\r\n"
     ]
    }
   ],
   "source": [
    "arguments[\"country\"] = \"Brazil\";\n",
    "capitalResponse = await kernel.InvokeAsync(capitalFunction, arguments);\n",
    "Console.WriteLine($\"Response: {capitalResponse}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "Large language models expose several parameters that control the behavior and quality of their responses. \n",
    "\n",
    "**Common Model Parameters:**\n",
    "- **Temperature:** Controls the randomness of the output. Lower values (e.g., 0.2) make the output more focused and deterministic, while higher values (e.g., 0.8) make it more creative and random.\n",
    "- **MaxTokens:** Limits the maximum number of tokens (words or word pieces) in the response. Useful for controlling the length of the output.\n",
    "- **TopP:** Makes the model pick from the most likely words until their total chance adds up to TopP (like 0.5). Lower values make the answer more focused.\n",
    "\n",
    "> **Note:** The exact set of parameters and their effects may vary depending on the model provider (OpenAI, Azure OpenAI, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Beneath the sky so vast and blue,  \n",
      "The ocean whispers, ancient, true.  \n",
      "Its waves compose a timeless song,  \n",
      "A dance of life, both fierce and strong.  \n",
      "\n",
      "The sunlit crest, the shadowed deep,  \n",
      "Hold secrets that the waters keep.  \n",
      "A mirror for the moonlit glow,  \n",
      "A realm where endless wonders grow.  \n",
      "\n",
      "Its tides embrace both shore and soul,  \n",
      "A restless heart, a ceaseless goal.  \n",
      "The ocean calls, a\r\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    " \n",
    "#pragma warning disable SKEXP0001\n",
    "var openAiPromptSettings = new OpenAIPromptExecutionSettings\n",
    "{\n",
    "    MaxTokens = 100,\n",
    "    Temperature = 0.5,\n",
    "    TopP = 0.8\n",
    "};\n",
    "#pragma warning restore SKEXP0001\n",
    "\n",
    "var chat = kernel.GetRequiredService<IChatCompletionService>(); \n",
    "// Create a prompt that will trigger the function call\n",
    "string prompt = \"Write a short poem about the ocean.\";\n",
    "var response = await chat.GetChatMessageContentAsync(\"Write a short poem about the ocean.\", openAiPromptSettings, kernel);\n",
    "Console.WriteLine($\"Response: {response}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adjust these parameters to experiment with different response styles and lengths. Try changing the temperature or max tokens and observe how the model's output changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using System Prompt and User Prompt\n",
    "\n",
    "Semantic Kernel allows you to provide both a system prompt (to guide the model's behavior) and a user prompt (the actual user input). This is useful for customizing the assistant's persona or instructions for a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Ahoy, matey! Ye seek to train a scallywag o' the skies, eh? Parrots be clever lil' crewmates, but teachin' 'em takes patience, savvy, an' a pocketful o' treats! Here's me best advice fer trainin' yer feathery friend:\n",
      "\n",
      "1. **Earn their trust**: Spend time lettin' yer bird get used to ye. Offer it treats, talk gently, an' never make it feel like it's walkin' the plank.\n",
      "\n",
      "2. **Use positive reinforcement**: Just like bribin’ a pirate crew, reward good behavior! Use tasty snacks like nuts or fruits, an’ give praise when yer parrot does somethin' right.\n",
      "\n",
      "3. **Teach simple tricks first**: Start small, like teachin' it to step up onto yer finger or perch. Say “step up” each time, so the clever critter learns the command.\n",
      "\n",
      "4. **Repetition be key**: Practice makes perfect, matey. Do short trainin’ sessions every day—10 to 15 minutes be enough fer their wee bird brains!\n",
      "\n",
      "5. **Squawk like a pirate!** If ye want ‘em to talk, repeat the words or phrases ye want ‘em to mimic. Keep it simple at first, like “Ahoy!” or “Shiver me timbers!” Parrots love enthusiasm!\n",
      "\n",
      "6. **Patience, ye scurvy dog**: Parrots be bright, aye, but they ain’t gonna learn overnight. Keep at it, an’ don’t let frustration sink yer ship.\n",
      "\n",
      "Remember, every parrot be different—some be fast learners, an’ some take their sweet time. Keep trainin’ fun as a treasure hunt, an’ soon yer bird will be the pride o’ the high seas!\n",
      "\n",
      "What say ye? Shall we get that parrot jawin’ like a buccaneer? 🦜☠️\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "// Improved Example: Using a detailed system prompt and a user prompt\n",
    "var systemPrompt = @\"You are a helpful assistant that talks like a pirate.\"; \n",
    "\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemPrompt);\n",
    "chatHistory.AddUserMessage(\"Hi, can you help me?\");\n",
    "chatHistory.AddAssistantMessage(\"Arrr! Of course, me hearty! What can I do for ye?\");\n",
    "chatHistory.AddUserMessage(\"What's the best way to train a parrot?\");\n",
    "\n",
    "var chat = kernel.GetRequiredService<IChatCompletionService>(); \n",
    "var chatResponse = await chat.GetChatMessageContentAsync(chatHistory);\n",
    "Console.WriteLine($\"Response: {chatResponse}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
