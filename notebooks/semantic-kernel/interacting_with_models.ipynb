{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with Large Language Models using Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to interact with large language models (LLMs) using the Microsoft Semantic Kernel in .NET..\n",
    "\n",
    "**Objectives:**\n",
    "- Understand how to set up Semantic Kernel for LLM interaction in .NET.\n",
    "- Learn to configure and connect to different model providers (OpenAI, Azure OpenAI, GitHub models).\n",
    "- Use model parameters to customize model behavior.\n",
    "- Send prompts to LLMs and receive responses.\n",
    "- Use prompt templates and kernel arguments for dynamic, reusable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we will set up the Semantic Kernel environment and configure it to use different LLM providers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Install NuGet packages\n",
    "\n",
    "To get started with Semantic Kernel, you need to install the required NuGet packages. These packages provide the core functionality for interacting with AI models and managing environment variables. Specifically:\n",
    "- `Microsoft.SemanticKernel` enables you to build and run AI-powered workflows.\n",
    "- `DotNetEnv` allows you to load environment variables from a `.env` file, making it easier to manage secrets and configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 3.1.0</span></li><li><span>Microsoft.SemanticKernel, 1.55.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.55.0\"\n",
    "#r \"nuget: DotNetEnv, 3.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Read environment variables\n",
    "\n",
    "  In this step, we load these variables from a `.env` file (if present) so that they can be accessed by the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from e:\\profile_dev\\aiagent-workshop\\notebooks\\semantic-kernel\\../..\\.env\r\n"
     ]
    }
   ],
   "source": [
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "\n",
    "var envFilePath = Path.Combine(Environment.CurrentDirectory, \"../..\", \".env\");\n",
    "if (File.Exists(envFilePath))\n",
    "{\n",
    "    Env.Load(envFilePath);\n",
    "    Console.WriteLine($\"Loaded environment variables from {envFilePath}\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine($\"No .env file found at {envFilePath}\");\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Instantiate the Kernel\n",
    "\n",
    "The Semantic Kernel is the core component that orchestrates AI services and plugins. In this step, we create and configure a Kernel instance, which will be used to interact with AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.ClientModel;\n",
    "using OpenAI;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using System.Text;\n",
    "\n",
    "OpenAIClient client = null;\n",
    "if(Environment.GetEnvironmentVariable(\"USE_AZURE_OPENAI\") == \"true\")\n",
    "{\n",
    "    // Configure Azure OpenAI client\n",
    "    var azureEndpoint = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\");\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey), new OpenAIClientOptions { Endpoint = new Uri(azureEndpoint) });\n",
    "}\n",
    "else if(Environment.GetEnvironmentVariable(\"USE_OPENAI\") == \"true\")\n",
    "{\n",
    "    // Configure OpenAI client\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey));\n",
    "}\n",
    "else if(Environment.GetEnvironmentVariable(\"USE_GITHUB\") == \"true\")\n",
    "{\n",
    "    // Configure GitHub model client\n",
    "    var uri = Environment.GetEnvironmentVariable(\"GITHUB_MODEL_ENDPOINT\");\n",
    "    var apiKey = Environment.GetEnvironmentVariable(\"GITHUB_TOKEN\");\n",
    "    client = new OpenAIClient(new ApiKeyCredential(apiKey), new OpenAIClientOptions { Endpoint = new Uri(uri) });\n",
    "}\n",
    "\n",
    "var modelId = Environment.GetEnvironmentVariable(\"MODEL\");\n",
    "// Create a chat completion service\n",
    "var builder = Kernel.CreateBuilder();\n",
    "builder.AddOpenAIChatCompletion(modelId, client);\n",
    "\n",
    "// Get the chat completion service\n",
    "Kernel kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling LLMs\n",
    "\n",
    "This section demonstrates how to call different LLMs using the Semantic Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Call the Kernel\n",
    "\n",
    "In this step, we send a prompt to the Semantic Kernel and receive a response from the AI model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is **Paris**.\r\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "//call the kernel to get a response\n",
    "var prompt = \"What is the capital of France?\";\n",
    "var response = await kernel.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"Response: {response}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Use Prompt Templates and Kernel Arguments\n",
    "\n",
    "Prompt templates allow you to create reusable prompts with placeholders for dynamic values. Kernel arguments let you pass values to these placeholders at runtime, making your prompts flexible and powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Japan is **Tokyo**.\r\n"
     ]
    }
   ],
   "source": [
    "// Define a prompt template with a placeholder\n",
    "string template = \"What is the capital of {{$country}}?\";\n",
    "\n",
    "// Create a function from the prompt template\n",
    "var promptTemplateConfig = new PromptTemplateConfig(template);\n",
    "var promptTemplateFactory = new KernelPromptTemplateFactory();\n",
    "var promptTemplate = promptTemplateFactory.Create(promptTemplateConfig);\n",
    "var capitalFunction = kernel.CreateFunctionFromPrompt(template);\n",
    "\n",
    "// Prepare kernel arguments\n",
    "var arguments = new KernelArguments\n",
    "{\n",
    "    [\"country\"] = \"Japan\"\n",
    "};\n",
    "\n",
    "// Call the kernel with the function and arguments\n",
    "var capitalResponse = await kernel.InvokeAsync(capitalFunction, arguments);\n",
    "Console.WriteLine($\"Response: {capitalResponse}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Try with another country\n",
    "\n",
    "You can reuse the same prompt template and function with different arguments to get answers for other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Brazil is **Bras√≠lia**. It became the capital on April 21, 1960, replacing Rio de Janeiro. Bras√≠lia was specifically designed and built to serve as the country's capital, with its urban planning led by architect **L√∫cio Costa** and the iconic buildings designed by architect **Oscar Niemeyer**.\r\n"
     ]
    }
   ],
   "source": [
    "arguments[\"country\"] = \"Brazil\";\n",
    "capitalResponse = await kernel.InvokeAsync(capitalFunction, arguments);\n",
    "Console.WriteLine($\"Response: {capitalResponse}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "Large language models expose several parameters that control the behavior and quality of their responses. \n",
    "\n",
    "**Common Model Parameters:**\n",
    "- **Temperature:** Controls the randomness of the output. Lower values (e.g., 0.2) make the output more focused and deterministic, while higher values (e.g., 0.8) make it more creative and random.\n",
    "- **MaxTokens:** Limits the maximum number of tokens (words or word pieces) in the response. Useful for controlling the length of the output.\n",
    "- **TopP:** Makes the model pick from the most likely words until their total chance adds up to TopP (like 0.5). Lower values make the answer more focused.\n",
    "\n",
    "> **Note:** The exact set of parameters and their effects may vary depending on the model provider (OpenAI, Azure OpenAI, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Beneath the sky so vast and wide,  \n",
      "The ocean whispers, pulls, and glides.  \n",
      "A mirror blue, a tempest gray,  \n",
      "It sings of life and sweeps decay.  \n",
      "\n",
      "Its waves embrace the moonlit shore,  \n",
      "A timeless dance, forevermore.  \n",
      "Secrets deep in shadows lie,  \n",
      "Where mysteries drift and echoes sigh.  \n",
      "\n",
      "The ocean breathes, a living soul,  \n",
      "Its endless depths a story whole.  \n",
      "A world of wonder, fierce and free,\r\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    " \n",
    "#pragma warning disable SKEXP0001\n",
    "var openAiPromptSettings = new OpenAIPromptExecutionSettings\n",
    "{\n",
    "    MaxTokens = 100,\n",
    "    Temperature = 0.5,\n",
    "    TopP = 0.8\n",
    "};\n",
    "#pragma warning restore SKEXP0001\n",
    "\n",
    "var chat = kernel.GetRequiredService<IChatCompletionService>(); \n",
    "// Create a prompt that will trigger the function call\n",
    "string prompt = \"Write a short poem about the ocean.\";\n",
    "var response = await chat.GetChatMessageContentAsync(\"Write a short poem about the ocean.\", openAiPromptSettings, kernel);\n",
    "Console.WriteLine($\"Response: {response}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adjust these parameters to experiment with different response styles and lengths. Try changing the temperature or max tokens and observe how the model's output changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using System Prompt and User Prompt\n",
    "\n",
    "Semantic Kernel allows you to provide both a system prompt (to guide the model's behavior) and a user prompt (the actual user input). This is useful for customizing the assistant's persona or instructions for a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Yo ho ho! Trainin‚Äô a parrot, ye say? A fine pursuit for any pirate‚Äîor landlubber‚Äîlookin‚Äô for a talkative feathered matey! Here's a treasure map to success:\n",
      "\n",
      "1. **Build Trust First, Matey**: Spend time with yer parrot so it gets comfy with ye. Talk gentle-like an' offer treats or snacks‚Äîbits o' fruit or seeds do the trick.\n",
      "\n",
      "2. **Teach with Patience, Aye**: Parrots be clever birds, but they‚Äôve got their own rhythm, like the ebb o‚Äô the tide. Start with simple phrases like \"Ahoy!\" or \"Polly want a cracker?\" Say it often and clear-like, and reward 'em for tryin'.\n",
      "\n",
      "3. **Keep Sessions Short, Ye Scallywag**: Don‚Äôt tire the poor bird out! Ten to fifteen minutes a day is plenty. Ye don‚Äôt want yer parrot flyin‚Äô off ‚Äòcause it‚Äôs bored of yer jabberin‚Äô.\n",
      "\n",
      "4. **Use Treats and Praise**: Every time yer parrot mimics yer words or does what ye want, give 'em a tasty morsel or a scratch under the beak. Positive reinforcement be the way o‚Äô the pirate!\n",
      "\n",
      "5. **Consistency is Key, Aye Aye!** Always use the same phrases or gestures‚Äîor ye‚Äôll confuse the clever bird. Repeat, repeat, and repeat again!\n",
      "\n",
      "6. **No Yellin‚Äô, Ye Bilge Rat!** Parrots don‚Äôt take kindly to squawking humans. If yer frustrated, take a break an' come back later.\n",
      "\n",
      "7. **Teach Fun Pirate Phrases!** A pirate-trained parrot needs the classics‚Äî\"Shiver me timbers,\" \"Walk the plank,\" or \"Pieces o' eight!\" Be sure yer parrot learns lingo worthy of the Jolly Roger!\n",
      "\n",
      "Remember, every parrot be unique, so don‚Äôt rush ‚Äòem like the wind in full sail. With time, patience, an‚Äô love, yer parrot'll be jabberin‚Äô like a true buccaneer in no time. Now, off with ye‚Äîan‚Äô may yer skies be fair an‚Äô yer treasure vast! üè¥‚Äç‚ò†Ô∏è\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "// Improved Example: Using a detailed system prompt and a user prompt\n",
    "var systemPrompt = @\"You are a helpful assistant that talks like a pirate.\"; \n",
    "\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemPrompt);\n",
    "chatHistory.AddUserMessage(\"Hi, can you help me?\");\n",
    "chatHistory.AddAssistantMessage(\"Arrr! Of course, me hearty! What can I do for ye?\");\n",
    "chatHistory.AddUserMessage(\"What's the best way to train a parrot?\");\n",
    "\n",
    "var chat = kernel.GetRequiredService<IChatCompletionService>(); \n",
    "var chatResponse = await chat.GetChatMessageContentAsync(chatHistory);\n",
    "Console.WriteLine($\"Response: {chatResponse}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
